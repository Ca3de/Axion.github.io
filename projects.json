{
    "projects": [
        {
            "title": "Project One",
            "description": "A brief description of Project One.",
            "image": "images/project1.jpg",
            "link": "https://github.com/yourusername/project-one",
            "embedCode": "<pre><code># Import required libraries
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, callbacks, models, optimizers
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import pandas as pd
import gc
from resnets_utils import *
from identity_block import *
from conv_block import *
from res_net import *

# Set image data format
tf.keras.backend.set_image_data_format('channels_last')

# Clear memory
gc.collect()

# Load dataset
X_train, Y_train_orig, X_test, _, class_labels = load_dataset()

# ==========================================================================
# PART 0 - Set Parameters
# ==========================================================================
img_width, img_height = 224, 224
classes = 196
batch_size = 64  # Adjust batch size to your system's memory
epochs = 10
patience = 10  # For callbacks
verbose = 1
num_models = 3  # Number of models in the ensemble
epsilon = 0.01  # FGSM perturbation strength
submission_file_path = "submission.csv"

# Normalize input data and ensure dtype is float32
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0

# Convert training labels to one-hot encoding and ensure dtype is float32
num_classes = 196
Y_train = tf.convert_to_tensor(convert_to_one_hot(Y_train_orig, num_classes).T, dtype=tf.float32)

# Create validation set
num_train_samples = int(0.8 * X_train.shape[0])  # 80% train, 20% validation
X_valid = X_train[num_train_samples:, :, :, :]
Y_valid = Y_train[num_train_samples:]
X_train = X_train[:num_train_samples, :, :, :]
Y_train = Y_train[:num_train_samples]

print(f"Training set: {X_train.shape}, Validation set: {X_valid.shape}")


# ==========================================================================
# PART 1 - Create the ResNet Model
# ==========================================================================
def create_model():
    model = ResNet(input_shape=(img_width, img_height, 3), classes=classes)
    optimizer = optimizers.Adam(learning_rate=0.001)
    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
    return model


# Initialize an ensemble of models
models = [create_model() for _ in range(num_models)]


# ==========================================================================
# PART 2 - FGSM Adversarial Example Generation
# ==========================================================================
# Adversarial Example Generation Function
# FGSM Adversarial Example Generation Function
def create_adversarial_examples(model, images, labels, epsilon):
    """
    Generate FGSM adversarial examples.
    """
    images = tf.convert_to_tensor(images, dtype=tf.float32)  # Ensure float32 dtype
    labels = tf.convert_to_tensor(labels, dtype=tf.float32)  # Ensure float32 dtype

    with tf.GradientTape() as tape:
        tape.watch(images)
        predictions = model(images, training=False)
        loss = tf.keras.losses.categorical_crossentropy(labels, predictions)

    gradients = tape.gradient(loss, images)
    if gradients is None:
        raise ValueError("Failed to compute gradients. Check model and data configuration.")
    signed_grad = tf.sign(gradients)
    adversarial_examples = images + epsilon * signed_grad
    adversarial_examples = tf.clip_by_value(adversarial_examples, 0, 1)  # Ensure valid pixel range

    return adversarial_examples  # Return tensor

# Training Step Function
@tf.function
def train_step(model, X_batch, y_batch, epsilon):
    """
    Perform one training step with clean and adversarial examples.
    """
    X_batch = tf.convert_to_tensor(X_batch, dtype=tf.float32)  # Ensure float32 dtype
    y_batch = tf.convert_to_tensor(y_batch, dtype=tf.float32)  # Ensure float32 dtype

    # Train on clean examples
    with tf.GradientTape() as tape:
        clean_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_batch, model(X_batch, training=True)))
    gradients = tape.gradient(clean_loss, model.trainable_variables)
    model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))

    # Generate adversarial examples
    adv_examples = create_adversarial_examples(model, X_batch, y_batch, epsilon)

    # Train on adversarial examples
    with tf.GradientTape() as tape:
        adv_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_batch, model(adv_examples, training=True)))
    adv_gradients = tape.gradient(adv_loss, model.trainable_variables)
    model.optimizer.apply_gradients(zip(adv_gradients, model.trainable_variables))

    return clean_loss, adv_loss

# ==========================================================================
# PART 4 - Checkpointing
# ==========================================================================
checkpoint_callback = callbacks.ModelCheckpoint(
    filepath="best_model.keras",
    monitor='val_accuracy',
    save_best_only=True,
    save_weights_only=False,
    verbose=1
)


# ==========================================================================
# PART 5 - Training Loop with Adversarial Training
# ==========================================================================
for i, model in enumerate(models):
    print(f"Training model {i + 1}/{num_models}")
    for epoch in range(epochs):
        print(f"Epoch {epoch + 1}/{epochs}")
        for step, (X_batch, y_batch) in enumerate(ImageDataGenerator().flow(X_train, Y_train, batch_size=batch_size)):
            y_batch = tf.convert_to_tensor(y_batch, dtype=tf.float32)  # Ensure float32 in batch
            clean_loss, adv_loss = train_step(model, X_batch, y_batch, epsilon)
            if step % 10 == 0:  # Log progress every 10 steps
                print(f"Step {step}, Clean Loss: {clean_loss:.4f}, Adversarial Loss: {adv_loss:.4f}")

        # Evaluate on validation set
        val_loss, val_acc = model.evaluate(X_valid, Y_valid, verbose=1)
        print(f"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}")

        # Save the best model using checkpointing
        checkpoint_callback.on_epoch_end(epoch, logs={"val_loss": val_loss, "val_accuracy": val_acc})


# ==========================================================================
# PART 6 - Ensemble Prediction
# ==========================================================================
def ensemble_predict(models, X_test):
    """
    Average predictions from all models in the ensemble.
    """
    predictions = np.zeros((X_test.shape[0], classes))
    for model in models:
        predictions += model.predict(X_test)
    predictions /= len(models)  # Average predictions
    return np.argmax(predictions, axis=1)


# Predict on the test set using the ensemble
ensemble_predictions = ensemble_predict(models, X_test)

# Map predictions to class labels
submission_data = {
    "ID": np.arange(1, len(ensemble_predictions) + 1),
    "Car_Model": [class_labels[class_id] for class_id in ensemble_predictions]
}
submission_df = pd.DataFrame(submission_data)

# Save submission to CSV
submission_df.to_csv(submission_file_path, index=False)
print(f"Submission file saved to {submission_file_path}")
;</code></pre>"
        },
        {
            "title": "Project Two",
            "description": "A brief description of Project Two.",
            "image": "images/project2.jpg",
            "link": "https://github.com/yourusername/project-two",
            "embedCode": "<pre><code>// Another Code Snippet\nfunction greet() { return 'Hi!'; }</code></pre>"
        }
        // Add more projects as needed
    ]
}
